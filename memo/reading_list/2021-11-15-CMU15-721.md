---
layout: memo
title: CMU15-721 Paper Reading Note
---

[2020 CPU15-721 reading list](https://15721.courses.cs.cmu.edu/spring2020/schedule.html)

# Topic 25: Databases on New Hardware - 2022/02/28
Paper : J. Arulraj, et al., Write-Behind Logging, in VLDB, 2016

## Commit protocol
Group commitはシステム内で高々1個しか走っていないことを前提としている(?)

変更毎にlog recordを作成する必要は無く、group commit毎に1 record作成すれば良い

## Note
2022現在、WBLの恩恵にあずかれそうなNVMは登場していないように思われる。
Intel Optane Persistent Memory (DCPMM)はrandom access速くない。

# Topic 24: Server-side Logic Execution - 2022/02/14
Paper : K. Ramachandra, et al., Froid: Optimization of Imperative Programs in a Relational Database, in VLDB, 2017

# Topic 23: Larger-than-Memory Databases - 2022/02/07
Paper : V. Leis, et al., LeanStore: In-Memory Data Management beyond Main Memory, in ICDE, 2018

実験結果から、バッファプールからのRandom evictionとLeanEvictの差がそれほど大きくない（最大0.5%）。
それならRandomでよいのでは？

# Topic 22: Cost Models - 2022/01/31
Paper : V. Leis, et al., How Good are Query Optimizers, Really?, in VLDB, 2015

Summary
> relational database systems produce large estimation errors that quickly grow as the number of joins increases, and that these errors are usually the reason for bad plans. In contrast to cardinality estimation, the contribution of the cost model to the overall query performance is limited.

## Estimates for Joins
> we observed different cardinality estimates of the same simple 2-join query depending on the syntactic order of the relations in the from and/or the join predicates in the where clauses!

Maybe because of calculation errors?

## Better Statistics for PostgreSQL
> the trend to underestimate cardinalities becomes even more pronounced. The reason is that the original, underestimated distinct counts resulted in higher estimates, which, accidentally, are closer to the truth. This is an example for the proverbial “two wrongs that make a right”, i.e., two errors that (partially) cancel each other out. Such behavior makes analyzing and fixing query optimizer problems very frustrating because fixing one query might break another.

join cardinarityの推定誤差が大きいため、各カラムが正しいdomain cardinarityを持っていても、最終的なjoin cardinarityの推定誤差は安定しない。
こうした挙動が、クエリオプティマイザの修正結果の予測を難しくし、分析を複雑化する要因となっている。

## Notes
- Joinのテーブル結合順序の組み合わせの総数はCatalan numberで表される
https://en.wikipedia.org/wiki/Catalan_number

# Topic 21: Optimizer Implementation (Alternative Approaches)
Paper : B. Ding, et al., Plan Stitch: Harnessing the Best of Many Plans, in VLDB, 2018

# Topic 20: Optimizer Implementation (Top-Down vs. Bottom-Up) - 2022/01/17
Paper : Yongwen Xu, Efficiency in the Columbia Database Query Optimizer (pages 1-35), in Portland State University, 1998

- Volcano: 最適化を始める前に全ての論理的等価な式を列挙する
- Cascade: 最適化ルールの適用により必要に応じて探索するのみ

# Topic 19: Optimizer Implementation (Overview) - 2021/12/20
Paper : S. Chaudhuri, An Overview of Query Optimization in Relational Systems, in PODS, 1998

- Interesting Order: 特定の列でソートされたテーブルを別のテーブルとして考える
  - 複数カラムによるソートはSystem Rでは考慮していない

## Optimizer Generator
- Starburst
  - 論理プラン(QGM)の最適化後物理プランを生成する
  - 今のDB2でも使われている
- Volcano/Cascade
  - 論理 -> 論理プラン、論理 -> 物理プランの最適化を同時に実施する

## Cascade Optimizer
- extensible optimizer of Cockroach DB
  - [opt形式で書かれたDSL](https://github.com/cockroachdb/cockroach/tree/master/pkg/sql/opt/norm/rules)で書き換えルールを列挙する

# Topic 18: Parallel Join Algorithms (Sorting) - 2021/12/13
Paper : C. Balkesen, et al., Multi-Core, Main-Memory Joins: Sort vs. Hash Revisited, in VLDB, 2013

- In register sort -> Sorting Network mentioned on 3.1
- In cache sort / Out of cache sort -> Bitonic Merge Network

Multi-way mergingのway数を増加することで、メモリ帯域の負荷を軽減しコンピュート負荷を増大する方向にチューニングできる。

# Topic 17: Parallel Join Algorithms (Hashing) - 2021/12/06
Paper : S. Schuh, et al., An Experimental Comparison of Thirteen Relational Equi-Joins in Main Memory, in SIGMOD, 2016

## Summary
> We immediately observe that even for this relatively simple query a major part of the runtime is spent in the non-join parts of the query. The time spent in the actual join is only about 10%–15% of the total runtime

## Notes

- Software Write Combining (SWWC)
  - 書き出すデータをキャッシュに収まるサイズの連続領域にバッファリングしてから、メモリに書き出すことでキャッシュミスを削減する実装技法
    - 書き込みアドレスが次々変わる場合、キャッシュミスにより性能が出ない -> バッファリングによりwrite回数が増えるがキャッシュミス低減により高速化
  - [reference](https://en.wikipedia.org/wiki/Write_combining#:~:text=Write%20combining%20(WC)%20is%20a,single%20bits%20or%20small%20chunks.)

- Non-temporal streaming
  - キャッシュをバイパスしメモリに書き込む命令
    - > if the code overwrites all the data in the cache line, then reading the cache line from memory could be considered an unnecessary performance overhead
  - > also referred to as "cache-bypassing" or "non-allocating" stores, and even "Non-Globally-Ordered stores" in some cases
  - [reference](https://sites.utexas.edu/jdm4372/2018/01/01/notes-on-non-temporal-aka-streaming-stores/)
  - [reference](https://lwn.net/Articles/255364/)

# Topic 16: Vectorization vs. Compilation - 2021/11/22
Paper : T. Kersten, et al., Everything You Always Wanted to Know About Compiled and Vectorized Queries But Were Afraid to Ask, in VLDB, 2018

- Vectorization (Tectorwise)
  - 各オペレータで細かいステップを踏まないといけない
  - 中間結果をマテリアライズする過程で命令数やキャッシュミスが増大
  - メモリストールが少ない
    - ベクトル化がキャッシュミスレイテンシを隠蔽
  - プリミティブ内のループが単純でありCPUのout-of-orderエンジンが効きやすい

- Compilation (Typer)
  - ループが複雑なため分岐予測ミスのペナルティが大きくなりやすい
  
- SIMD
  - メモリネックだとほとんど効かない。キャッシュに乗っていて初めて効果あり
  
- Conclusion  
  - 計算インテンシブなクエリであればdata-centricクエリコンパイラ
  - 結合や集約で大きなハッシュテーブルにアクセスするメモリバウンドなクエリであればベクトル化インタプリタ
  - SIMD、マルチスレッド、ハードウェアの影響は軽微

# Topic 15: Vectorized Execution - 2021/11/29
Paper : O. Polychroniou, et al., Rethinking SIMD Vectorization for In-Memory Databases, in SIGMOD, 2015

- Hash Table Build  
scatterを使うが、keyが衝突すると、scatterの仕様によりレジスタの右側の値が残り他の値が失われる  
-> 衝突検知が必要  
-> keys_outにuniqueな値を一度格納し、再度取り出す。その結果を元の値とマッチすることを確認することで衝突が検知できる。  
ShufflingのConflict Serializationでも同様の仕組みで衝突を検知する。

- Partitioning
  1. build histogram
  2. decide partition boundaries based on the histogram by Prefix Sum
  3. write keys to partitions
    - conflict serialization

SIMDは実世界のRDBMSでどの程度使用されているか? -> vector wiseやDB2のカナムナストアで使用されている

# Topic 14: Query Compilation - 2021/11/15
Paper : T. Neumann, Efficiently Compiling Efficient Query Plans for Modern Hardware, in VLDB, 2011

## Reference
[my note](https://www.slideshare.net/keisuke-suzuki/db-reading-group-may-16-2018)

# Topic 13: Query Execution & Processing - 2021/11/01, 08
Paper : M. Kester, et al., Access Path Selection in Main-Memory Optimized Data Systems: Should I Scan or Should I Probe?, in SIGMOD, 2017

## Modeling In-Memory Shared Scan
- PEで2を掛けているのはレンジクエリで上限と下限の比較で2回演算が必要なため

# Topic 11: Networking Protocols - 2021/10/18
Paper : M. Raasveldt, et al., Don't Hold My Data Hostage: A Case for Client Protocol Redesign, in VLDB, 2017

## Result Set Serialization
### postgres result set wire format
- per-row metadataサイズが実際のデータサイズを超えてしまっていた
  - 多くのmetadataが冗長になっており無駄が多い

### Hive result set wrire format 
- null maskが値毎に1byte消費しており非効率
- columnar formatにもかかわらず転送が遅いのは整数の可変長エンコーディングのオーバーヘッドが原因か

# Topic 10: Recovery Protocols - 2021/10/11
Paper : P. Antonopoulos, et al., Constant Time Recovery in Azure SQL Database, in VLDB, 2019 

## Compensation log records (CLR)
Undo処理中のcrash発生時に処理済みのUndoをreplayするためのlog

## Recovery protocol
2a Redo lock acquisitionはactive txのロックを獲得する -> Redo後にtxを受け付けるため。

Instant recovery: Redo対象のロックを獲得し、Redo開始と共にtxを受け付ける。
本論文のSQL serverの例ではcheckpoint頻度が高いのでRedoはあまり多くない。

Redo -> parallel
Undo -> おそらくparallel?

Oldest Dirty Page LSNはどの時点のLSNか -> ?

## Checkpointing
ARIESはDirty Page TableとTransaction Tableを書き出す。Dirty Page自体はcheckpointでは書き出さない。(fuzzy checkpoint)

## CTR
Checkpointログの直後に前回のcheckpointからの間に生じたSLogを集約したログを書く。
-> Oldest Transaction Begin LSN -> Min(..)間のlogを処理せず済む

UndoはSLogのみ。Undoは対象のversionにmarkするだけで後でGCする

GCはpage単位

### Logical Revert
各versionはstateを持っている Active / Committed / Aborted

Abort処理時は書いたversionをAbortedにするのみ。

### Redo Locking Optimization
Recovery中にLockを取りたいケースがある
- Read only secondaryのcrash recovery
- Unresolved Distributed Transactions

### Questions
constantに近いrecovery timeを実現するために、頻繁にcheckpointをやっているがcheckpointが遅れることはないか?

# Topic 9: Database Compression
Paper : D. Abadi, et al., Integrating Compression and Execution in Column-Oriented Database Systems, in SIGMOD, 2006

# Topic 8: Storage Models, Data Layout, & System Catalogs - 2021/09/27
Paper : M. Athanassoulis, et al., Optimal Column Layout for Hybrid Workloads, in VLDB, 2019

[slide](https://docs.google.com/presentation/d/1m34wY6Pq6xyutZX5s0gEQ4x9fgoiExY97U4sMXBQprs/edit?usp=sharing)

# Topic 7: OLTP Indexes (Trie Data Structures) - 2021/09/13
Paper : V. Alvarez, et al., A Comparison of Adaptive Radix Trees and Hash Tables, in ICDE, 2015
## 奇数木の特徴
- キー分布、キー長に対する耐性が低い -> 水平方向、垂直方向の圧縮
- 格納済みのキーの数や格納順に対応する耐性が高い

## JudyL
Bitmap nodeがポインタをインターリーブしている理由は、子ノードへのポインタの追加を高速に行うため。

## Quadratic Probing
Open Addressing scheme: ハッシュ値が衝突した時、規則に従ってハッシュテーブルの別の要素をプローブして最初に見つかった空き位置に格納する。

## Cuckoo Hash
ハッシュテーブルの枚数を増やすことで、負荷率（ハッシュテーブルの充填率）を上げられメモリ効率がよくなる。
トレードオフとしてread速度が遅くなる。

Bucketingによるメモリ効率の向上はないが、ハッシュの充填率をあげることができることを確認している。
これにより、リハッシュの頻度を下げられる。

# Topic 6: OLTP Indexes (B+Tree Data Structures) - 2021/09/06
Paper : Z. Wang, et al., Building A Bw-Tree Takes More Than Just Buzz Words, in SIGMOD, 2018
## Bw-Tree
- Node has 64 bit logical node ID
  - physical memory address is obtained by consulting the Mapping Table
- Nodes refer to other nodes by ID (logical links)
- The Mapping Table allows to atomically change the physical location of a node 
without acquiring locks by single atomic compare-and-swap

## Node search shortcut
Narrowing down search range by the key and the offset attribute of delta while traversing the chain.

## Optimistic lock coupling
ロックとバージョンカウンタを使用する。
- write operation: ロックを取得し、アンロック時にバージョンカウンタをインクリメントする
- read operation: ロックは取得しない。オペレーション開始時にバージョンカウンタの値を確認し、終了時にバージョンカウンタが変わっていないことを確認する。バージョンカウンタが異なる場合はabort -> restartする。

reference: Viktor Leis, Florian Scheibner, Alfons Kemper, and Thomas Neumann. 2016. The ART of practical synchronization. In DaMoN.

# Topic 5: Multi-Version Concurrency Control (Garbage Collection) - 2021/08/30
Paper : J. Böttcher, et al., Scalable Garbage Collection for In-Memory MVCC Systems, in VLDB, 2019
## Problem
MVCCシステムにおいて、ロングトランザクションによってGCできず、バージョンチェインが伸びることで
生じる性能低下の問題。
従来のハイウォーターマークのみを管理する手法では、バージョンチェインの途中のガーベジを回収できない。

## GC Tracking level
epoch based systemはOLTPのシステムでGCのオーバーヘッドを軽減するのに相性が良い。

# Topic 4: Multi-Version Concurrency Control (Protocols) - 2021/08/23
Paper : T. Neumann, et al., Fast Serializable Multi-Version Concurrency Control for Main-Memory Database Systems, in SIGMOD, 2015

## Version access
startTimeを払い出すタイミングをtxの開始時ではなく、最初のread時に払い出すことで、
新しいバージョンを読める可能性が上がり、readの性能が向上する可能性がある。

## Serializability Validation
- write - write conflict  
書き込み時に検知。後続txがabortする。
- read - write conflict  
commit時のvalidationで検知。txのライフタイム（[startTime, commitTime]）の間にcommitされたtxのみを検査すれば良い。  
Validation時にPredicate logからper relationのPredicate Treeを構築し、自分のreadしたpredicateと一致するパスの存在を調べる。

## Summary
Read intensiveなワークロードでは、自txのread predicateと他txのWrite setを比較することで、
自分のRead setを再スキャンするよりvalidationのオーバーヘッドを計算量、スペース共に低減することができる。

## Misc
SIGMOD 2019の AOCC (adaptive optimistic concurrency control) という論文で、hyperのconflict checkの方式を部分的に採用してる。
Read setが大きくなるような (OLAPもあるような) ワークロードでは有利だが、Read setが小さいOLTP的なワークロードだと
Predicate setの並行制御がボトルネックになることがある。

# Topic 3: Multi-Version Concurrency Control (Design Decisions) - 2021/08/16
Paper : Y. Wu, et al., An Empirical Evaluation of In-Memory Multi-Version Concurrency Control, in VLDB, 2017

## Summary
従来はOLTPのスケーラビリティ向上のためにはConcurrency control protocolが最重要と考えられていたが、
実はVersion Storageの設計がより性能に大きな影響を与えていると考えられる。

## Concurrency Control Protocol
### MVTO
- TPC-Cでは最も良いスループットに。不向きなワークロードは?
- Well-knownなDBMS（論文中のTable 1）で、MVTOは使用されていない。  
-> 複数のisolation levelの提供が難しいのが理由の1つか。

### MVOCC
- New versionは、1VOCCのようにthread localに書くのではなく、共通領域に書く。
- abortがcommit時なのでペナルティが大きい。
- validationにおけるread setのスキャンのオーバーヘッドが大きい。

### MV2PL + WAIT_DIE
- Read txにロックを取られている場合、write txがabortするため、write txのabort率が高くなる。

### Serialization Certifier (SI + SSN)
- abort率を低減できるが、centralized anti-dependency graphの管理がスケーラビリティのbottleneckになる。

## Garbage Collection
### Epoch-based memory management
- Thread localにqueueを持ち、centralized threadが全threadをチェックして、全てepochが0ならGC可と判定する(?)

### Background Vacuuming
定期的にDBをフルスキャンしてガーベジを回収する方法は、大規模DBではスケールしにくい。
latch-freeデータ構造でガーベジを管理し、epochベースで回収する方法や、dirty blockのビットマップを用いて
ガーベジの存在するブロックのみをスキャンする（postgresのvisibility mapなど）方法など、ガーベジの
探索方法の工夫が必要。

### Cooperative Vacuuming
version chainの走査時に、ガーベジの検出を同時に行う。O2N append onlyストレージのみで使用できる。
スキャン頻度が低いタプルがGCされないdusty corners問題が発生する。

# Topic 2: In-Memory Databases - 2021/08/02
Paper : X. Yu, et al., Staring into the Abyss: An Evaluation of Concurrency Control with One Thousand Cores, in VLDB, 2014
## Basic T/O
トランザクションtがタプルxに対して、read/writeを行う際に
`x.MAX_READ_TS`/`x.MAX_WRITE_TS`とtのタイムスタンプを比較して、大きい場合のみread/writeができる。
Repeatable Readのためread時にスレッドローカルにデータをコピーする。

## Timestamp Allocation
- Mutex
- [XADD](https://en.wikipedia.org/wiki/Fetch-and-add) (この論文で使用)
- XADD batch (Silo)
- CPU clock + thread ID
  - [invariant tsc](https://www.intel.com/content/dam/www/public/us/en/documents/manuals/64-ia-32-architectures-software-developer-vol-2b-manual.pdf) (p.545) on Intel CPU 
  - http://oliveryang.net/2015/09/pitfalls-of-TSC-usage/
  - https://forums.guru3d.com/threads/a-bit-detailed-info-on-intel-time-stamp-counter-tsc.433977/
  - https://linuxtut.com/en/0ea82f8856fea48fd2d6/
- HW実装のTSアロケータ（この論文ではGraphiteで実装）

## 5.2 write-intensive workload
fig.9b: Useful worklockが多いが、ロックグラフの生成に時間を消費しており、thrashingによって性能が落ちた。

# Topic 1: Course Introduction and History of Databases - 2021/07/26
Paper : A. Pavlo, et al., What's New with NewSQL?, in SIGMOD Record (vol. 45, iss. 2), 2016

## 背景
2000年代、インターネットアプリケーションの台頭で、同時接続数の大幅な増加や常時オンラインの要件が必要とされるようになり、
DBがボトルネックとなることが多くなりました。
DBのスケールアップでは費用対効果が悪く、スケールアウトにより処理能力を向上する方法が模索されました。
そうした中で現れたのがNoSQLのデータストアです。
トラディショナルなDBMSのモデルでは、性能と可用性を犠牲に一貫性と正確性が重視されましたが、
このトレードオフは多くのWebアプリケーションでは妥当ではないと考えられました。
また、キーによる単純な検索クエリにはSQLはオーバーキルであるという見方もありました。
NoSQLを使う利点は、スケーラビリティのことは気にせず、アプリケーションの開発に専念でき、
高い生産性を実現できることにあると考えられていました。

しかし結局のところ、多くのアプリケーションではトランザクションや一貫性の保証が重要であることがわかってきました。
アプリケーションで一貫性を保証するコストは高く、またトランザクションによる抽象化が人の理解を容易にするため、
生産性が高くなるという意見もあります。
そこで、2010年代になると、NoSQL並みのスケーラビリティを確保しつつ、ACIDを保証するNewSQLが現れました。
2000年代中盤から、VerticaやGreenplumといったOLAP向けDBMSで、スケールアウトに対応するものはありましたが、
これらはOLAP特化のため、この論文ではNewSQLには含めないと述べられています。
NewSQLは、トランザクショナルな読み書き必要とし、データ全体の一部をインデックス走査で読む短時間のクエリが、
異なるインプットに対して繰り返し実行されるといったワークロードをもつアプリケーションに特化しています。

## NewSQLの分類
この論文では、NewSQLを以下の3種類に分類にしています。
（ScaleDB, Hekaton, CitusDB, VitesseなどのシングルノードDBMSのストレージエンジン拡張はNewSQLに含めない）
- 新しいアーキテクチャでスクラッチ開発されたもの
  - Examples: Clustrix, CockroachDB, Google Spanner, H-Store, HyPer, MemSQL, NuoDB, SAP HANA, VoltDB
- 2000年代にGoogleなどによって開発されたミドルウェアによるシャーディングを再実装したもの
  - Examples: AgilData Scalable Cluster, MariaDB MaxScale, ScaleArc
- クラウドコンピューティングプロバイダによるDBaaS
  - Examples: Amazon Aurora, ClearDB
  - Auorora MySQLはmulti-masterをサポートするものの、コンフリクトのハンドリングなどで制限もあり、スケールアウトでどの程度性能向上するか不明

## Main memory storage
メモリの大容量化、低価格化を背景に、NewSQLでもメモリベースアーキテクチャのDBが見られるようになってきました。
メモリベースアーキテクチャのアイディア自体は、1980年代から見られましたが、NewSQLで目新しいのは、
メモリフットプリントを抑えるため、2次記憶へのデータの部分書き出しをサポートするといった工夫がみられる点です。

トラディショナルなDBMSでは、トランザクション処理等で大半の処理時間を専有しており、
意味のあるデータ処理を実行している時間は10%以下だった、などといった研究も見られており、
現代のハードウェアに合わせたアーキテクチャの見直しによって、DBMSの大幅な性能向上も期待されるところです。
[OLTP Through the Looking Glass, and What We Found There](https://dl.acm.org/doi/10.1145/1376616.1376713)

## Sharding / Partitioning
ともにホモジニアスなクラスタ構成をとる、NuoDBとMemSQLのシャーディング戦略について解説しています。
NuoDBでは、Transaction Engine（TE）が、Storage Manager（SM）によって分割されたデータブロック（atom）をキャッシュしており、
またデータが同じTEによって処理されやすくなるようなロードバランシングを行っています。
結果として、NuoDBでは事前のパーティショニングやテーブル間の関係なくして、他の分散DBMSと同様のパーティショニングを実現しています。

また、MemSQLでは、クエリ実行のみの集約ノードと、データを格納するリーフノードという構成をとり、リーフノードにクエリをプッシュダウン
することで、ノード間のデータ転送量を削減しています。

これらのNewSQLでは再パーティショニングなしで、ノード追加が可能です。（NuoDBのTE、MemSQLの集約ノード）

また、パーティションのライブマイグレーションといった、再パーティショニングの運用負荷を低減する仕組みもNoSQL / NewSQLではみられます。

## Concurrency control
ほとんどのNewSQLは、デッドロック検知の難しさから2PLを避ける傾向にあります。
最近では代わりに、Timestamp Ordering（TO）をベースにしたものが多いです。
NewSQLで広く用いられるプロトコルとして、ロングランニングなリードオンリークエリを、ライトをブロックせずに
実行できるという利点から、decentralized multi-version concurrency controlが用いられています。

Google Spannerのコンカレンシコントロール実装は一石を投じるもので、ベースは2PL + MVCCですが、ユニークな点として
GPSや原子時計といったハードウェアにより、高精度の時刻同期を実現しています。
Spannerの登場により、従来は分散DBMSに向かないと考えられていたTOが見直されました。
CockroachDBは、hybrid clock protocolによって原子時計無しで、Spannerと同等のコンカレンシコントロールを実現しています。
[Hybrid clock protocol of CockroachDB](https://www.cockroachlabs.com/blog/living-without-atomic-clocks/)

## まとめと今後の展望
NewSQLで用いられている技術の多くは、過去に発見されたものですが、それらの技術は個々のシステムで単発で
実装されたもので、1つのプラットフォームとして組み合わされたものではありませんでした。
NewSQLの革新性は、ハードウェアの進歩や、高並列度のOLTP、大規模データのOLAPを必要とする
アプリケーションが増加したことにより、膨大なエンジニアリングによってプラットフォームとして
作りあげられたことにあります。

NewSQLの台頭により、今後は分散DBMSがコモディティ化していくのではないかと考えられます。
これからは、リアルタイムデータ分析やhybrid transaction-analytics processing（HTAP）といった、
過去データと新しいデータの組み合わせから知見を得るためのシステムへと進化していくと著者達は予測しています。


## memo
- [Calvin](http://cs.yale.edu/homes/thomson/publications/calvin-sigmod12.pdf) flow control
- [RAMP](https://people.eecs.berkeley.edu/~alig/papers/ramp.pdf)
- Secondary indexのデータの持ち方について
  OLTPとOLAPでスキャンの特性が異なるためレイアウトを分けたい。
  HTAPでOLAP側へのレプリケーションにおいて、再レイアウトのオーバーヘッドをどうするか｡

# General Notes
- CMU's education purpose DBMS has nice tests [BusTub](https://github.com/cmu-db/bustub)
- [System design primer](https://github.com/donnemartin/system-design-primer)

